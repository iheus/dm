{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analyzing Data using Python\n",
    "By Shuhei Kitamura"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "1. Preparing Data for Analysis\n",
    "    - Importing Data\n",
    "    - Combining Data\n",
    "    - Reshaping Data  \n",
    "    - Making Variables\n",
    "    - Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 300 # set # of rows to display \n",
    "pd.options.display.max_columns = 100 # set # of columns to display "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir('...') # set the working directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Preparing Data for Analysis\n",
    "- We already have cleaned data. The next step is to make the final data for analysis.\n",
    "- In this exercise, we will put eight files together. How?\n",
    "    - 1. Append US Senate election data\n",
    "    - 2. Append daily temperature data\n",
    "    - 3. Merge them\n",
    "- Our goal is to make the data that have a panel structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Importing Data\n",
    "- Import data as usual. Recall that all files are saved in csv format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "elec_data = {}\n",
    "temp_data = {}\n",
    "for year in range(2008,2016,2):\n",
    "    elec_data['elec_'+str(year)] = pd.read_csv('data/elec_senate_'+str(year)+'.csv', dtype=object)\n",
    "    temp_data['elec_'+str(year)] = pd.read_csv('data/daily_temp_'+str(year)+'.csv')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Check data entries and their types, if you do not know them yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combining Data\n",
    "#### - Appending\n",
    "- Recall that we have used `concatenate` to combine NumPy arrays (see, python_basics_4.ipynb).\n",
    "- You can do the similar thing using `concat` for Pandas' objects.\n",
    "    - `concat` can be used for both appending and merging data.\n",
    "    - `append` and `merge` are also available. We will use `merge` later.\n",
    "- Append `data1` and `data2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(np.random.rand(3,3), columns=['var1', 'var2', 'var3'], index=['a', 'b', 'c'])\n",
    "data2 = pd.DataFrame(np.random.rand(3,3), columns=['var1', 'var2', 'var3'], index=['a', 'b', 'c'])\n",
    "print(data1); print(data2)\n",
    "print(pd.concat([data1, data2])); print(pd.concat([data1, data2], ignore_index=True))\n",
    "print(pd.concat([data1, data2], axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- What happens if some columns are missing in one of the datasets?\n",
    "- If you want to keep them, use `outer` option, otherwise use `inner` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame(np.random.rand(2,2), columns=['var1', 'var2'], index=['a', 'b'])\n",
    "data2 = pd.DataFrame(np.random.rand(3,3), columns=['var1', 'var2', 'var3'], index=['a', 'b', 'c'])\n",
    "print(data1); print(data2)\n",
    "print(pd.concat([data1, data2], ignore_index=True, join='inner'))\n",
    "print(pd.concat([data1, data2], ignore_index=True, join='outer', sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Let's combine all years for election data and temperature data, respectively.\n",
    "- Wait... but temperature data are already very long (> 250,000 observations).\n",
    "- Let's reduce the sizes of datasets before appending them.\n",
    "    - Why didn't we do it when we cleaned data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### - Group Aggregation\n",
    "- Our goal is to keep a single observation for each state and year. \n",
    "- How? There are several strategies.\n",
    "    - Take the mean/max/min/std, etc.\n",
    "    - Keep some of the observations\n",
    "    - Reshape data\n",
    "- I suggest the following procedure:\n",
    "    1. Keep the Election Day temperature\n",
    "    2. Take the mean of `'arithmetic_mean'` (daily average) and the max and mean of `'1st_max_value'` (daily max) for each state.\n",
    "- Does it make sense to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Let's keep the Election Day temperature for each year.\n",
    "    - Election Day: November 4th, 2008, November 2nd, 2010, November 6th, 2012, November 8th, 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "temp_data['elec_2008'] = temp_data['elec_2008'].loc[temp_data['elec_2008']['date_local'] == '2008-11-04',]\n",
    "temp_data['elec_2010'] = temp_data['elec_2010'].loc[temp_data['elec_2010']['date_local'] == '2010-11-02',]\n",
    "temp_data['elec_2012'] = temp_data['elec_2012'].loc[temp_data['elec_2012']['date_local'] == '2012-11-06',]\n",
    "temp_data['elec_2014'] = temp_data['elec_2014'].loc[temp_data['elec_2014']['date_local'] == '2014-11-08',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Next, check whether any columns of interest have missing values before aggregating their values.\n",
    "    - Recall that some computation methods do not igore missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- A powerful method for aggregation is `groupby`.\n",
    "- If you get an error when executing the following code, you need to update `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "for year in range(2008,2016,2):\n",
    "    temp_data['elec_'+str(year)+'_agg'] = temp_data['elec_'+str(year)].groupby('state_name').agg(temp_mean=('arithmetic_mean', np.mean), temp_max_max=('1st_max_value', np.max), temp_max_mean=('1st_max_value', np.mean)).reset_index()\n",
    "    temp_data['elec_'+str(year)+'_agg']['elec_year'] = str(year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Finally, it's time to append data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "elec_all = elec_data['elec_2008'] \n",
    "temp_all = temp_data['elec_2008_agg']\n",
    "for year in range(2010,2016,2):\n",
    "    elec_all = pd.concat([elec_all, elec_data['elec_'+str(year)]], ignore_index=True)\n",
    "    temp_all = pd.concat([temp_all, temp_data['elec_'+str(year)+'_agg']], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Check that each dataset contains state names and election years.\n",
    "- Do you notice something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(elec_all['state_long'].unique()); print(elec_all['elec_year'].unique())\n",
    "print(temp_all['state_name'].unique()); print(temp_all['elec_year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### - Removing spaces\n",
    "- Some strings contain strange spaces in `elec_all`. This is often the case.\n",
    "- We have to remove it. Otherwise, we will not be able to merge data properly later.\n",
    "- There are several ways to remove spaces. However, in this case, it's unwise to use `.str.strip()` or `.str.replace(\" \",\"\")`, which removes all spaces in a given string. Why?\n",
    "- Let's remove the right-side spaces using `str.rstrip()`.\n",
    "    - To remove the left-side spaces, use `str.lstrip()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "elec_all['state_long'] = elec_all['state_long'].str.rstrip() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- What about now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "print(elec_all['state_long'].unique()); print(elec_all['elec_year'].unique())\n",
    "print(temp_all['state_name'].unique()); print(temp_all['elec_year'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### - Merging\n",
    "- Merging means that you combine data horizontally.\n",
    "- To merge Pandas' objects, use `merge`.\n",
    "    - You can also use `concat` but `merge` seems to be more flexible and intuitive.\n",
    "- Merge `data1` and `data2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame([['tom', 9], ['jerry', 12]], columns=['name', 'educ'], index=['a', 'b'])\n",
    "data2 = pd.DataFrame([['tom', 185, 70], ['jerry', 170, 62], ['spike', 165, 60]], columns=['name', 'height', 'weight'], index=['a', 'b', 'c'])\n",
    "print(data1); print(data2)\n",
    "print(pd.merge(data1, data2, on='name')) # inner join (intersection)\n",
    "print(pd.merge(data1, data2, on='name', how='outer')) # outer join (union)\n",
    "print(pd.merge(data1, data2, on='name', how='right'))  # right join (keep right data)\n",
    "print(pd.merge(data1, data2, on='name', how='left')) # left join (keep left data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The keys can have different names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame([['tom', 9], ['jerry', 12]], columns=['name1', 'educ'], index=['a', 'b'])\n",
    "data2 = pd.DataFrame([['tom', 185, 70], ['jerry', 170, 62], ['spike', 165, 60]], columns=['name2', 'height', 'weight'], index=['a', 'b', 'c'])\n",
    "print(data1); print(data2)\n",
    "print(pd.merge(data1, data2, left_on='name1', right_on='name2', how='outer')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- You can use more than one key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame([['tom', 2000, 9], ['jerry', 2000, 12]], columns=['name', 'year', 'educ'], index=['a', 'b'])\n",
    "data2 = pd.DataFrame([['tom', 2000, 185, 70], ['jerry', 2000, 170, 62], ['tom', 2001, 187, 75], ['jerry', 2001, 171, 63]], columns=['name', 'year', 'height', 'weight'], index=['a', 'b', 'c', 'd'])\n",
    "print(data1); print(data2)\n",
    "print(pd.merge(data1, data2, on=['name', 'year'], how='outer'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- What happens if two datasets have the same column name with different values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame([['tom', 185], ['jerry', 170]], columns=['name', 'height'], index=['a', 'b'])\n",
    "data2 = pd.DataFrame([['tom', 185, 70], ['jerry', 172, 62]], columns=['name', 'height', 'weight'], index=['a', 'b'])\n",
    "print(data1); print(data2)\n",
    "print(pd.merge(data1, data2, on='name'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Let's merge election and temperature data.\n",
    "    - What are the keys?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data_use = pd.merge(elec_all, temp_all, left_on=['state_long', 'elec_year'], right_on=['state_name', 'elec_year'], how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Print `data_use`, which should be in a long format. You will often use this type of data structure for the panel data analysis.\n",
    "- What do you think a wide format may look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reshaping Data\n",
    "- If necessary, reshape data for analysis. In that case, use `pivot`.\n",
    "    - In our case, we don't need to reshape the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data_use_to_reshape = data_use.loc[data_use['state_long'].notna(),]\n",
    "data1 = data_use_to_reshape.pivot(index='state_long', columns='elec_year') # reshape to a wide format\n",
    "data2 = data1.stack() # back to a long format\n",
    "data3 = data2.unstack() # back to a wide format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Making Variables\n",
    "- You may need more variables for analysis. For example:\n",
    "    - Logarithm\n",
    "    - Total, mean, min, max...\n",
    "    - Share, ratio...\n",
    "- Let's make \n",
    "    - Vote share of Republican and Democratic candicates\n",
    "    - Natural logarithm of temperature    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# make vote shares\n",
    "data_use['gelec_total'] = data_use['gelec_dem'].astype(float).fillna(0) + data_use['gelec_rep'].astype(float).fillna(0) + data_use['gelec_oth'].astype(float).fillna(0)\n",
    "#print(data_use.loc[data_use['gelec_total'] == 0.0,])\n",
    "data_use.loc[data_use['gelec_total'] == 0.0, 'gelec_total'] = np.nan # replace to NaN if the total vote is zero\n",
    "data_use['rep_share'] = data_use['gelec_rep'].astype(float) / data_use['gelec_total'] # republican vote share\n",
    "data_use['dem_share'] = data_use['gelec_dem'].astype(float) / data_use['gelec_total'] # democrat vote share\n",
    "#print(data_use.loc[:, ['gelec_dem', 'gelec_rep', 'gelec_oth', 'gelec_total', 'rep_share']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# take natural logs\n",
    "data_use['ln_temp_mean'] = np.log(data_use['temp_mean'])\n",
    "data_use['ln_temp_max_max'] = np.log(data_use['temp_max_max'])\n",
    "data_use['ln_temp_max_mean'] = np.log(data_use['temp_max_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Saving Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "data_use.to_csv('data/data_use.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
